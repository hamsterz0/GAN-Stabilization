{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS269.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "_baD78ErF6JY",
        "colab_type": "code",
        "outputId": "34739325-698c-4342-a161-29f027426254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.2.post3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ommkPL67GBDQ",
        "colab_type": "code",
        "outputId": "4d961ff7-fdc9-4684-8f39-a70f8b930bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor()])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1000,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4YMZ_yK6Pne7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Usage\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.modules.utils import _single, _pair, _triple\n",
        "from torch.nn.modules.conv import _ConvNd\n",
        "from torch.nn.modules import Module\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "import math\n",
        "\n",
        "__all__ = ['SVDConv2d']\n",
        "\n",
        "\n",
        "class SVDConv2d(Module):\n",
        "    '''\n",
        "    W = UdV\n",
        "    '''\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, k, stride=1,\n",
        "                padding=0, dilation=1, groups=1, bias=True, norm = False):\n",
        "        self.eps = 1e-8\n",
        "        self.norm = norm\n",
        "\n",
        "        kernel_size = _pair(kernel_size)\n",
        "        stride = _pair(stride)\n",
        "        padding = _pair(padding)\n",
        "        dilation = _pair(dilation)\n",
        "        super(SVDConv2d, self).__init__()\n",
        "\n",
        "        if in_channels % groups != 0:\n",
        "            raise ValueError('in_channels must be divisible by groups')\n",
        "        if out_channels % groups != 0:\n",
        "            raise ValueError('out_channels must be divisible by groups')\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.total_in_dim = in_channels*kernel_size[0]*kernel_size[1]\n",
        "        self.weiSize = (self.out_channels,in_channels,kernel_size[0],kernel_size[1])\n",
        "\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.output_padding = _pair(0)\n",
        "        self.groups = groups\n",
        "\n",
        "        self.scale = Parameter(torch.Tensor(1))\n",
        "        self.scale.data.fill_(1)\n",
        "\n",
        "        # TODO: set k to min(out,total_in) if not set\n",
        "        # validation checks on k\n",
        "        \n",
        "        if self.out_channels  <= self.total_in_dim:\n",
        "            self.Uweight = Parameter(torch.Tensor(self.out_channels, k))#\n",
        "            self.Dweight = Parameter(torch.Tensor(k))#\n",
        "            self.Vweight = Parameter(torch.Tensor(k, self.total_in_dim))#\n",
        "            self.Uweight.data.normal_(0, math.sqrt(2. / self.out_channels))\n",
        "            self.Vweight.data.normal_(0, math.sqrt(2. / self.total_in_dim))\n",
        "            self.Dweight.data.fill_(1)\n",
        "        else:\n",
        "            self.Uweight = Parameter(torch.Tensor(self.out_channels, k))#\n",
        "            self.Dweight = Parameter(torch.Tensor(k))#\n",
        "            self.Vweight = Parameter(torch.Tensor(k, self.total_in_dim))#\n",
        "            self.Uweight.data.normal_(0, math.sqrt(2. / self.out_channels))\n",
        "            self.Vweight.data.normal_(0, math.sqrt(2. / self.total_in_dim))\n",
        "            self.Dweight.data.fill_(1)\n",
        "        self.projectiter = 0\n",
        "        self.project(style='qr', interval = 1)\n",
        "\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.Tensor(self.out_channels))#\n",
        "            self.bias.data.fill_(0)\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "\n",
        "        if norm:\n",
        "            self.register_buffer('input_norm_wei',torch.ones(1, in_channels // groups, *kernel_size))\n",
        "\n",
        "    def update_sigma(self):\n",
        "        self.Dweight.data = self.Dweight.data/self.Dweight.data.abs().max()\n",
        "\n",
        "    def spectral_reg(self):\n",
        "        return -(torch.log(self.Dweight)).mean()\n",
        "\n",
        "    @property\n",
        "    def W_(self):\n",
        "        self.update_sigma()\n",
        "        return self.Uweight.mm(self.Dweight.diag()).mm(self.Vweight).view(self.weiSize)*self.scale\n",
        "\n",
        "    def forward(self, input):\n",
        "        _output = F.conv2d(input, self.W_, self.bias, self.stride,\n",
        "                        self.padding, self.dilation, self.groups)\n",
        "        return _output\n",
        "\n",
        "    def orth_reg(self):\n",
        "        penalty = 0\n",
        "\n",
        "        if self.out_channels  <= self.total_in_dim:\n",
        "            W = self.Uweight\n",
        "        else:\n",
        "            W = self.Uweight.t()\n",
        "        Wt = torch.t(W)\n",
        "        WWt = W.mm(Wt)\n",
        "        I = Variable(torch.eye(WWt.size()[0]).cuda())\n",
        "        penalty = penalty+((WWt.sub(I))**2).sum()\n",
        "\n",
        "\n",
        "        W = self.Vweight\n",
        "        Wt = torch.t(W)\n",
        "        WWt = W.mm(Wt)\n",
        "        I = Variable(torch.eye(WWt.size()[0]).cuda())\n",
        "        penalty = penalty+((WWt.sub(I))**2).sum()\n",
        "        return penalty\n",
        "\n",
        "    def project(self, style='none', interval = 1):\n",
        "        '''\n",
        "        Project weight to l2 ball\n",
        "        '''\n",
        "        self.projectiter = self.projectiter+1\n",
        "        if style=='qr' and self.projectiter%interval == 0:\n",
        "            # Compute the qr factorization for U\n",
        "            '''\n",
        "            if self.out_channels  <= self.total_in_dim:\n",
        "                q, r = torch.qr(self.Uweight.data.t())\n",
        "            else:\n",
        "                q, r = torch.qr(self.Uweight.data)\n",
        "            # Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\n",
        "            d = torch.diag(r, 0)\n",
        "            ph = d.sign()\n",
        "            q *= ph\n",
        "            if self.out_channels  <= self.total_in_dim:\n",
        "                self.Uweight.data = q.t()\n",
        "            else:\n",
        "                self.Uweight.data = q\n",
        "            '''    \n",
        "                \n",
        "            # Compute the qr factorization for V\n",
        "            q, r = torch.qr(self.Uweight.data)\n",
        "            # Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\n",
        "            d = torch.diag(r, 0)\n",
        "            ph = d.sign()\n",
        "            q *= ph\n",
        "            self.Uweight.data = q\n",
        "\n",
        "            # Compute the qr factorization for V\n",
        "            q, r = torch.qr(self.Vweight.data.t())\n",
        "            # Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf\n",
        "            d = torch.diag(r, 0)\n",
        "            ph = d.sign()\n",
        "            q *= ph\n",
        "            self.Vweight.data = q.t()\n",
        "        elif style=='svd' and self.projectiter%interval == 0:\n",
        "            # Compute the svd factorization (may be not stable) for U\n",
        "            u, s, v = torch.svd(self.Uweight.data)\n",
        "            self.Uweight.data = u.mm(v.t())\n",
        "\n",
        "            # Compute the svd factorization (may be not stable) for V\n",
        "            u, s, v = torch.svd(self.Vweight.data)\n",
        "            self.Vweight.data = u.mm(v.t())\n",
        "\n",
        "    def showOrthInfo(self):\n",
        "        s= self.Dweight.data\n",
        "        _D = self.Dweight.data.diag()\n",
        "        W = self.Uweight.data.mm(_D).mm(self.Vweight.data)\n",
        "        _, ss, _ = torch.svd(W.t())\n",
        "        print('Singular Value Summary: ')\n",
        "        print('max :',s.max().item(),'max* :',ss.max().item())\n",
        "        print('mean:',s.mean().item(),'mean*:',ss.mean().item())\n",
        "        print('min :',s.min().item(),'min* :',ss.min().item())\n",
        "        print('var :',s.var().item(),'var* :',ss.var().item())\n",
        "        print('s RMSE: ', ((s-ss)**2).mean().item()**0.5)\n",
        "        if self.out_channels  <= self.total_in_dim:\n",
        "            pu = (self.Uweight.data.mm(self.Uweight.data.t())-torch.eye(self.Uweight.size()[0]).cuda()).norm().item()**2\n",
        "        else:\n",
        "            pu = (self.Uweight.data.t().mm(self.Uweight.data)-torch.eye(self.Uweight.size()[1]).cuda()).norm().item()**2\n",
        "        pv =  (self.Vweight.data.mm(self.Vweight.data.t())-torch.eye(self.Vweight.size()[0]).cuda()).norm().item()**2\n",
        "        print('penalty :', pu, ' (U) + ', pv, ' (V)' )\n",
        "        return ss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TpzLyL1XHdoz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class network(nn.Module):\n",
        "  \n",
        "  def __init__(self, k):\n",
        "    super(network, self).__init__()\n",
        "    self.conv1 = SVDConv2d(3, 10, 3, k)\n",
        "    \n",
        "  def forward(self, input):\n",
        "    return self.conv1(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KPItocMaQA5o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "x, y = next(iter(trainloader))\n",
        "model_10 = network(10).type(torch.cuda.FloatTensor)\n",
        "model_3 = network(3).type(torch.cuda.FloatTensor)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bN6gGiLpQEla",
        "colab_type": "code",
        "outputId": "37d91cf4-016b-46d9-8393-fbdde8b4f615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "x = Variable(x).type(torch.cuda.FloatTensor)\n",
        "model_10(x)\n",
        "end = time.time()\n",
        "print(end-start)\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "x = Variable(x).type(torch.cuda.FloatTensor)\n",
        "model_3(x)\n",
        "end = time.time()\n",
        "print(end-start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.001901388168334961\n",
            "0.0010929107666015625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AGmzoQS2R5Cx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}